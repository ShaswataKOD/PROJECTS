{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":841326,"sourceType":"datasetVersion","datasetId":444017},{"sourceId":8968935,"sourceType":"datasetVersion","datasetId":5399328}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport numpy as np # For numerical operations\nimport pandas as pd # For data processing (not used in this part, but useful for data-related tasks)\nimport cv2 # For computer vision tasks (image processing and video capture)\nimport matplotlib.pyplot as plt # For displaying images\n\n# Install and import the MTCNN library for face detection\n!pip install mtcnn\nfrom mtcnn import MTCNN\n\n# Initialize the MTCNN detector for face detection\ndetector = MTCNN()\n","metadata":{"_uuid":"75c48c9a-ff03-4508-be1a-57dd92e8e09a","_cell_guid":"227c6924-95e0-4fbd-ba72-5b1e1b5f5d70","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load and process an image\nimg_path = '/kaggle/input/screenshotimage/Screenshot (142).png' # Path to the image\nimg = cv2.imread(img_path) # Read the image from the file\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert the image from BGR to RGB\n\n# Detect faces in the image\noutput = detector.detect_faces(img_rgb)\n\n# Process each detected face\nfor face in output:\n    x, y, width, height = face['box'] # Get bounding box coordinates\n\n    # Draw a rectangle around the detected face\n    cv2.rectangle(img_rgb, (x, y), (x + width, y + height), (255, 0, 0), 3)\n\n    # Draw facial keypoints (like eyes, nose, mouth)\n    for key, value in face['keypoints'].items():\n        cv2.circle(img_rgb, value, 3, (0, 255, 0), -1)\n        \n\n# Display the processed image with detected faces using Matplotlib\nplt.figure(figsize=(8, 6))\nplt.imshow(img_rgb)\nplt.axis('off') # Turn off axis\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# video capture from the default camera\ncap = cv2.VideoCapture(0)\ndetector = MTCNN() # Initialize the MTCNN detector\n\nwhile True:\n    ret, frame = cap.read() # Read a frame from the video capture\n\n    if not ret:\n        break # Break the loop if no frame is captured\n\n    # Detect faces in the current frame\n    output = detector.detect_faces(frame)\n\n    # Draw bounding boxes around detected faces in the video frame\n    for face in output:\n        x, y, width, height = face['box']\n        cv2.rectangle(frame, (x, y), (x + width, y + height), (255, 0, 0), 3)\n\n    # Show the frame with detected faces\n    cv2.imshow('win', frame)\n\n    # Break the loop if 'x' key is pressed\n    if cv2.waitKey(1) & 0xFF == ord('x'):\n        break\n\ncap.release() # Release the video capture object\n# cv2.destroyAllWindows() # Close all OpenCV windows (commented out for environments where this may not work)","metadata":{},"execution_count":null,"outputs":[]}]}